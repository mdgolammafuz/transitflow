# config/app.docker.yml  (mounted as /app/config/app.yaml)

artifacts_dir: artifacts

embedding:
  model_name: sentence-transformers/all-MiniLM-L6-v2
  device: cpu

retrieval:
  top_k: 5
  max_k: 20

generation:
  max_context_chars: 6000
  
llm:
  provider: ollama
  model: phi3:mini
  base_url: http://intelsent-ollama:11434
  temperature: 0.1
  max_tokens: 256

db:
  conn_str: postgresql://intel:intel@pgvector:5432/intelrag

pgvector:
  enabled: true
  conn: postgresql://intel:intel@pgvector:5432/intelrag
  table: chunks
  text_col: content